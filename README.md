# Fair-ML-Classifiers-for-Dementia
## Introduction Fairness and Fair Machine Learning Classifiers

Before developing any fair classifieres, we should need answer the following questions: 
1. “How can we formulate fairness such that it can be considered in ML systems for mental health applications”. 
2. "A fair ML should be fair for a group of individuals or just for individuals?"  
To answer the first question, we should consider that anti-discrimination laws the fairness of any ML algorithms can be defined based on two notions: 

## Disparate treatment: it focuses to verify if an ML system considers the subject’s sensitive attribute while
## Disparate impact: considers if results of a ML system can disproportionately hurt or benefit people with certain sensitive attribute values (e.g., females, blacks)

To answer the second question, we should consider that any ML algorithms can be fair for a group or can be fair for an individuals 


## Group fairness: ensures some form of statistical parity (e.g. between positive outcomes or errors) for members of different protected groups (e.g. gender or race). 
## Individual fairness
On the other hand, individual fairness ensures that people who are ‘similar’ with respect to the classification task receive similar outcomes. These measures appear to conflict in cases where, as a result of trying to satisfy group fairness, pairs of individuals who are otherwise identical but differ in a protected characteristic are assigned different outcomes.



## Introduction to Dementia and Machine Learning for Dementia
